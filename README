=======================================
Optimizations of the Common Convolution
Samuel L Owens
==============
This collection shows various stages along the optimization process using convolutions as an example

Step 1: Basic Sequential Implementation : sequential_basic.cpp
	this is the first functional build 
	no attention is paid to optimizations
	simply proves the solution is valid 
	:
	my solution is very basic, it should be understandable to most anyone familiar with c/c++

Step 2: Optimized Sequential Implementation : sequential_opt.cpp
	this is the first round of optimizations
	remove any redundant instructions 
	minimize variable initializations
	merge for loops to minimize iteration instructions
	target edge cases with optimized solution variants
	this might look longer and more complicated but the output should be identical
	:
	my solution becomes more complex
	each edge case is given its own targeted function
		this removes redundant if statements
	for loops are collapsed where one of their dimensions was the same
		this removes redundant iteration instructions
	variables initializations are minimized 


Step 3: Basic Multithreaded : multi_basic.cpp
	this is the first attempt at a multithreaded solution
	if possible take your sequential solution and parallelize it
	openmp allows simple generic parallelizations without much effort
	carve your solution into steps that dont rely on one another 
	do each of those asynchronously with respect to the others
	sometimes you will need to rework your solution to be more parallel
	some things simply cannot be parallelized efficiently
	:
	this solution basically takes the optimized sequential solution and does it asynchronously
	this is a good example of OMP's ease of use,
	create a new task for each step of the solution that can be done asynchronously
	the core is treated as a single chunk


Step 4: Optimized Multithreaded : multi_opt_1.cpp
	this is the first round of optimizations to the multithreaded solution
	perhaps you've simply plugged in an omp instruction to your sequential with tweaking
	perhaps you've come to a new solution with more parallelization
	first repeat/revisit the optimizations of Step 2, you may have created some new redundancies
		it is possible some of your optimizations may be detrimental to parallelization
	now decide how large of chunks you should be working on,
		perhaps you should carve your work up further
		perhaps there are some memory access patterns in your solution
			optimizing to those patterns may yield significant speed up
		perhaps some things you are parallelizing are insignificant
			starting a new thread takes time and that is time not spent on your computations
	:
	this optimizes upon the previously multithreaded solution
	the core is the best remaining avenue for increased parallelism
	carving the core into chunks is the best way to do this 
	alternating threads in a cell by cell nature 
		where a cell from thread0 is directly next to a cell from thread1
		you will lose benefits from cachelines being larger than cell values in terms of bytes
		larger cachelines means each of the cores will read in a contiguous piece of memory
		because of how arrays are typically allocated the values are going to be continuous
		so each core is going to have multiple adjacent values in it's cache at a time
	so we parallelize by chunks not by cells
	it is recommended to carve the array vertically and horizontally
	I have simply used OMP to carve it vertically, each thread will operate on 32 rows
	this lines up reasonably well with the cache sizes on my cpu
	I achieve aproximately ( N_CORESx ) speedup when allowing N_CORES cpu threads 

		
Step 5.1: CPU Architecture Targeting
	this is the final step in optimizations on the CPU side
	rework your solution to take advantage of AVX, SSE, SIMD, etc
		find what instruction sets are available on your architecture
		take advantage of the ones that might be helpful to you
	sometimes this can be a simple process 
	sometimes this can mean completely reworking your solution
	this almost always gives significant performance improvements
	using compiler optimizations can work well, often better than handwritten optimizations
		g++/gcc : -O1, -O2, -O3 for increasing levels of optimization
		be sure to verify the compiler does not optimize away things it believes are redundant
		it will delete parts of your solution if it thinks they dont matter
		it is more aggressive about this as you increase the level, 3 is the most aggressive

step 5.2: GPU Acceleration
	some problems benefit from gpu acceleration 
	for these problems CUDA is a tremendous tool if you have an NVIDIA gpu
	OPENCL is okay too 
	MPI works if youre brave
	each of these are different and have different optimization oportunities


